{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Low-Rank Autoregressive Tensor Completion (LATC)\n",
    "\n",
    "- **CPU implementation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def ten2mat(tensor, mode):\n",
    "    return np.reshape(np.moveaxis(tensor, mode, 0), (tensor.shape[mode], -1), order = 'F')\n",
    "\n",
    "def mat2ten(mat, tensor_size, mode):\n",
    "    index = list()\n",
    "    index.append(mode)\n",
    "    for i in range(tensor_size.shape[0]):\n",
    "        if i != mode:\n",
    "            index.append(i)\n",
    "    return np.moveaxis(np.reshape(mat, tensor_size[index].tolist(), order = 'F'), 0, mode)\n",
    "\n",
    "def svt_tnn(mat, tau, theta):\n",
    "    [m, n] = mat.shape\n",
    "    if 2 * m < n:\n",
    "        u, s, v = np.linalg.svd(mat @ mat.T, full_matrices = 0)\n",
    "        s = np.sqrt(s)\n",
    "        idx = np.sum(s > tau)\n",
    "        mid = np.zeros(idx)\n",
    "        mid[: theta] = 1\n",
    "        mid[theta : idx] = (s[theta : idx] - tau) / s[theta : idx]\n",
    "        return (u[:, : idx] @ np.diag(mid)) @ (u[:, : idx].T @ mat)\n",
    "    elif m > 2 * n:\n",
    "        return svt_tnn(mat.T, tau, theta).T\n",
    "    u, s, v = np.linalg.svd(mat, full_matrices = 0)\n",
    "    idx = np.sum(s > tau)\n",
    "    vec = s[: idx].copy()\n",
    "    vec[theta : idx] = s[theta : idx] - tau\n",
    "    return u[:, : idx] @ np.diag(vec) @ v[: idx, :]\n",
    "\n",
    "def compute_mape(var, var_hat):\n",
    "    return np.sum(np.abs(var - var_hat) / var) / var.shape[0]\n",
    "\n",
    "def compute_rmse(var, var_hat):\n",
    "    return  np.sqrt(np.sum((var - var_hat) ** 2) / var.shape[0])\n",
    "\n",
    "def print_result(it, tol, var, var_hat):\n",
    "    print('Iter: {}'.format(it))\n",
    "    print('Tolerance: {:.6}'.format(tol))\n",
    "    print('Imputation MAPE: {:.6}'.format(compute_mape(var, var_hat)))\n",
    "    print('Imputation RMSE: {:.6}'.format(compute_rmse(var, var_hat)))\n",
    "    print()\n",
    "\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "def generate_Psi(dim_time, time_lags):\n",
    "    Psis = []\n",
    "    max_lag = np.max(time_lags)\n",
    "    for i in range(len(time_lags) + 1):\n",
    "        row = np.arange(0, dim_time - max_lag)\n",
    "        if i == 0:\n",
    "            col = np.arange(0, dim_time - max_lag) + max_lag\n",
    "        else:\n",
    "            col = np.arange(0, dim_time - max_lag) + max_lag - time_lags[i - 1]\n",
    "        data = np.ones(dim_time - max_lag)\n",
    "        Psi = coo_matrix((data, (row, col)),\n",
    "                         shape = (dim_time - max_lag, dim_time)).tocsr()\n",
    "        Psis.append(Psi)\n",
    "    return Psis\n",
    "\n",
    "def update_cg(var, r, d, Ad, rold):\n",
    "    alpha = rold / np.inner(d, Ad)\n",
    "    var = var + alpha * d\n",
    "    r = r - alpha * Ad\n",
    "    rnew = np.inner(r, r)\n",
    "    d = r + (rnew / rold) * d\n",
    "    return var, r, d, rnew\n",
    "\n",
    "def ell_z(Z, double_A, Psi_T_Psi, lmbda, N, d):\n",
    "    temp = lmbda * Z\n",
    "    i = 0\n",
    "    for k in range(d + 1):\n",
    "        for h in range(d + 1):\n",
    "            temp += (double_A[i].reshape([N, 1]) * (Z @ Psi_T_Psi[i]))\n",
    "            i += 1\n",
    "    return temp\n",
    "\n",
    "def conj_grad_z(eq_right, Z, double_A, Psi_T_Psi, time_lags, lmbda, maxiter = 5):\n",
    "    N, T = Z.shape\n",
    "    z = np.reshape(Z, -1, order = 'F')\n",
    "    r = np.reshape(eq_right - ell_z(Z, double_A, Psi_T_Psi,\n",
    "                                    lmbda, N, len(time_lags)), -1, order = 'F')\n",
    "    d = r.copy()\n",
    "    rold = np.inner(r, r)\n",
    "    for it in range(maxiter):\n",
    "        D = np.reshape(d, (N, T), order = 'F')\n",
    "        Ad = np.reshape(ell_z(D, double_A, Psi_T_Psi,\n",
    "                              lmbda, N, len(time_lags)), -1, order = 'F')\n",
    "        z, r, d, rold = update_cg(z, r, d, Ad, rold)\n",
    "    return np.reshape(z, (N, T), order = 'F')\n",
    "\n",
    "def LATC(dense_tensor, sparse_tensor, time_lags, alpha, gamma, lmbda, theta,\n",
    "         epsilon = 1e-4, maxiter = 100, K = 3):\n",
    "    \"\"\"Low-Rank Autoregressive Tensor Completion (LATC)\"\"\"\n",
    "\n",
    "    dim = np.array(sparse_tensor.shape)\n",
    "    dim_time = int(np.prod(dim) / dim[0])\n",
    "    d = len(time_lags)\n",
    "    sparse_mat = ten2mat(sparse_tensor, 0)\n",
    "    pos_missing = np.where(sparse_mat == 0)\n",
    "    pos_test = np.where((dense_tensor != 0) & (sparse_tensor == 0))\n",
    "    dense_test = dense_tensor[pos_test]\n",
    "    del dense_tensor\n",
    "\n",
    "    W_tensor = np.zeros(dim)\n",
    "    Z_tensor = sparse_tensor.copy()\n",
    "    Z = sparse_mat.copy()\n",
    "    A = 0.001 * np.random.rand(dim[0], d)\n",
    "    Psis = generate_Psi(dim_time, time_lags)\n",
    "    it = 0\n",
    "    ind = np.zeros((d, dim_time - time_lags[-1]), dtype = np.int_)\n",
    "    for i in range(d):\n",
    "        ind[i, :] = np.arange(time_lags[-1] - time_lags[i], dim_time - time_lags[i])\n",
    "    Psi_T_Psi = []\n",
    "    for k in range(d + 1):\n",
    "        for h in range(d + 1):\n",
    "            Psi_T_Psi.append(Psis[h].T @ Psis[k])\n",
    "    last_mat = sparse_mat.copy()\n",
    "    snorm = np.linalg.norm(sparse_mat, 'fro')\n",
    "    while True:\n",
    "        A_new = np.append(-np.ones(dim[0]).reshape([dim[0], 1]), A, axis = 1)\n",
    "        double_A = []\n",
    "        for k in range(d + 1):\n",
    "            for h in range(d + 1):\n",
    "                double_A.append(gamma * A_new[:, k] * A_new[:, h])\n",
    "        for k in range(K):\n",
    "            lmbda = min(lmbda * 1.05, 1e5)\n",
    "            tensor_hat = np.zeros(dim)\n",
    "            for s in range(len(dim)):\n",
    "                tensor_hat += alpha[s] * mat2ten(svt_tnn(ten2mat(Z_tensor - W_tensor / lmbda, s),\n",
    "                                                         alpha[s] / lmbda, theta), dim, s)\n",
    "            eq_right = lmbda * ten2mat(tensor_hat + W_tensor / lmbda, 0)\n",
    "            Z[pos_missing] = conj_grad_z(eq_right, Z, double_A, Psi_T_Psi,\n",
    "                                         time_lags, lmbda)[pos_missing]\n",
    "            Z_tensor = mat2ten(Z, dim, 0)\n",
    "            W_tensor = W_tensor + lmbda * (tensor_hat - Z_tensor)\n",
    "        for m in range(dim[0]):\n",
    "            A[m, :] = np.linalg.lstsq(Z[m, ind].T, Z[m, time_lags[-1] :], rcond = None)[0]\n",
    "        mat_hat = ten2mat(tensor_hat, 0)\n",
    "        tol = np.linalg.norm((mat_hat - last_mat), 'fro') / snorm\n",
    "        last_mat = mat_hat.copy()\n",
    "        it += 1\n",
    "        if it % 200 == 0:\n",
    "            print_result(it, tol, dense_test, tensor_hat[pos_test])\n",
    "        if (tol < epsilon) or (it >= maxiter):\n",
    "            break\n",
    "    print_result(it, tol, dense_test, tensor_hat[pos_test])\n",
    "\n",
    "    return tensor_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On the Seattle Freeway Traffic Speed Dataset\n",
    "\n",
    "### Random Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "for r in [0.3, 0.7, 0.9]:\n",
    "    print('Missing rate = {}'.format(r))\n",
    "    missing_rate = r\n",
    "\n",
    "    ## Random missing (RM)\n",
    "    dense_tensor = np.load('tensor.npz')['arr_0'].transpose(0, 2, 1)\n",
    "    dim1, dim2, dim3 = dense_tensor.shape\n",
    "    np.random.seed(1000)\n",
    "    sparse_tensor = dense_tensor * np.round(np.random.rand(dim1, dim2, dim3) + 0.5 - missing_rate)\n",
    "\n",
    "    for c in [1/10, 1/5, 1, 5, 10]:\n",
    "        for theta in [5, 10, 15, 20, 25]:\n",
    "            print('c = {}'.format(c))\n",
    "            print('theta = {}'.format(theta))\n",
    "            start = time.time()\n",
    "            time_lags = np.arange(1, 7)\n",
    "            alpha = np.ones(3) / 3\n",
    "            lmbda = 1e-5\n",
    "            gamma = c * lmbda\n",
    "            tensor_hat = LATC(dense_tensor, sparse_tensor, time_lags,\n",
    "                              alpha, gamma, lmbda, theta)\n",
    "            end = time.time()\n",
    "            print('Running time: %d seconds'%(end - start))\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-Random Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "for r in [0.3, 0.7]:\n",
    "    print('Missing rate = {}'.format(r))\n",
    "    missing_rate = r\n",
    "\n",
    "    ## Non-random Missing (NM)\n",
    "    dense_tensor = np.load('tensor.npz')['arr_0'].transpose(0, 2, 1)\n",
    "    dim1, dim2, dim3 = dense_tensor.shape\n",
    "    np.random.seed(1000)\n",
    "    sparse_tensor = dense_tensor * np.round(np.random.rand(dim1, dim3) + 0.5 - missing_rate)[:, None, :]\n",
    "\n",
    "    for c in [1/10, 1/5, 1, 5, 10]:\n",
    "        for theta in [5, 10, 15, 20, 25]:\n",
    "            print('c = {}'.format(c))\n",
    "            print('theta = {}'.format(theta))\n",
    "            start = time.time()\n",
    "            time_lags = np.arange(1, 7)\n",
    "            alpha = np.ones(3) / 3\n",
    "            lmbda = 1e-5\n",
    "            gamma = c * lmbda\n",
    "            tensor_hat = LATC(dense_tensor, sparse_tensor, time_lags,\n",
    "                              alpha, gamma, lmbda, theta)\n",
    "            end = time.time()\n",
    "            print('Running time: %d seconds'%(end - start))\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Block-Out Missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "for r in [0.3]:\n",
    "    print('Missing rate = {}'.format(r))\n",
    "    missing_rate = r\n",
    "\n",
    "    ## Block-out Missing (BM)\n",
    "    dense_tensor = np.load('tensor.npz')['arr_0'].transpose(0, 2, 1)\n",
    "    dim1, dim2, dim3 = dense_tensor.shape\n",
    "    block_window = 12\n",
    "    np.random.seed(1000)\n",
    "    vec = np.random.rand(int(dim2 * dim3 / block_window))\n",
    "    temp = np.array([vec] * block_window)\n",
    "    vec = temp.reshape([dim2 * dim3], order = 'F')\n",
    "    sparse_tensor = dense_tensor * mat2ten(np.ones((dim1, dim2 * dim3)) * np.round(vec + 0.5 - missing_rate)[None, :], np.array([dim1, dim2, dim3]), 0)\n",
    "\n",
    "    for c in [1/10, 1/5, 1, 5, 10]:\n",
    "        for theta in [5, 10, 15, 20, 25]:\n",
    "            print('c = {}'.format(c))\n",
    "            print('theta = {}'.format(theta))\n",
    "            start = time.time()\n",
    "            time_lags = np.arange(1, 5)\n",
    "            alpha = np.ones(3) / 3\n",
    "            lmbda = 1e-5\n",
    "            gamma = c * lmbda\n",
    "            tensor_hat = LATC(dense_tensor, sparse_tensor, time_lags,\n",
    "                              alpha, gamma, lmbda, theta)\n",
    "            end = time.time()\n",
    "            print('Running time: %d seconds'%(end - start))\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On the Portland Traffic Volume Dataset\n",
    "\n",
    "### Random Missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "for r in [0.3, 0.7, 0.9]:\n",
    "    print('Missing rate = {}'.format(r))\n",
    "    missing_rate = r\n",
    "\n",
    "    # Random Missing (RM)\n",
    "    dense_mat = np.load('volume.npy')\n",
    "    dim1, dim2 = dense_mat.shape\n",
    "    dim = np.array([dim1, 96, 31])\n",
    "    dense_tensor = mat2ten(dense_mat, dim, 0)\n",
    "    np.random.seed(1000)\n",
    "    sparse_tensor = mat2ten(dense_mat * np.round(np.random.rand(dim1, dim2) + 0.5 - missing_rate), dim, 0)\n",
    "\n",
    "    for c in [1/10, 1/5, 1, 5, 10]:\n",
    "        for theta in [5, 10, 15, 20, 25]:\n",
    "            print('c = {}'.format(c))\n",
    "            print('theta = {}'.format(theta))\n",
    "            start = time.time()\n",
    "            time_lags = np.arange(1, 5)\n",
    "            alpha = np.ones(3) / 3\n",
    "            lmbda = 1e-5\n",
    "            gamma = c * lmbda\n",
    "            tensor_hat = LATC(dense_tensor, sparse_tensor, time_lags,\n",
    "                              alpha, gamma, lmbda, theta)\n",
    "            end = time.time()\n",
    "            print('Running time: %d seconds'%(end - start))\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-Random Missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "for r in [0.3, 0.7]:\n",
    "    print('Missing rate = {}'.format(r))\n",
    "    missing_rate = r\n",
    "\n",
    "    # Non-random Missing (NM)\n",
    "    dense_mat = np.load('volume.npy')\n",
    "    dim1, dim2 = dense_mat.shape\n",
    "    dim = np.array([dim1, 96, 31])\n",
    "    dense_tensor = mat2ten(dense_mat, dim, 0)\n",
    "    np.random.seed(1000)\n",
    "    sparse_tensor = dense_tensor * np.round(np.random.rand(dim1, dim[2]) + 0.5 - missing_rate)[:, None, :]\n",
    "\n",
    "    for c in [1/10, 1/5, 1, 5, 10]:\n",
    "        for theta in [5, 10, 15, 20, 25]:\n",
    "            print('c = {}'.format(c))\n",
    "            print('theta = {}'.format(theta))\n",
    "            start = time.time()\n",
    "            time_lags = np.arange(1, 5)\n",
    "            alpha = np.ones(3) / 3\n",
    "            lmbda = 1e-5\n",
    "            gamma = c * lmbda\n",
    "            tensor_hat = LATC(dense_tensor, sparse_tensor, time_lags,\n",
    "                              alpha, gamma, lmbda, theta)\n",
    "            end = time.time()\n",
    "            print('Running time: %d seconds'%(end - start))\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Block-Out Missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "for r in [0.3]:\n",
    "    print('Missing rate = {}'.format(r))\n",
    "    missing_rate = r\n",
    "\n",
    "    ## Block-out Missing (BM)\n",
    "    dense_mat = np.load('volume.npy')\n",
    "    dim1, dim2 = dense_mat.shape\n",
    "    dim = np.array([dim1, 96, 31])\n",
    "    dense_tensor = mat2ten(dense_mat, dim, 0)\n",
    "    block_window = 4\n",
    "    np.random.seed(1000)\n",
    "    vec = np.random.rand(int(dim2 / block_window))\n",
    "    temp = np.array([vec] * block_window)\n",
    "    vec = temp.reshape([dim2], order = 'F')\n",
    "    sparse_tensor = mat2ten(dense_mat * np.round(vec + 0.5 - missing_rate)[None, :], dim, 0)\n",
    "\n",
    "    for c in [1/10, 1/5, 1, 5, 10]:\n",
    "        for theta in [5, 10, 15, 20, 25]:\n",
    "            print('c = {}'.format(c))\n",
    "            print('theta = {}'.format(theta))\n",
    "            start = time.time()\n",
    "            time_lags = np.arange(1, 5)\n",
    "            alpha = np.ones(3) / 3\n",
    "            lmbda = 1e-5\n",
    "            gamma = c * lmbda\n",
    "            tensor_hat = LATC(dense_tensor, sparse_tensor, time_lags,\n",
    "                              alpha, gamma, lmbda, theta)\n",
    "            end = time.time()\n",
    "            print('Running time: %d seconds'%(end - start))\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### License\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>This work is released under the MIT license.</b>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
