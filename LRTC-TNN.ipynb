{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Low-Rank Tensor Completion (LRTC-TNN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import inv as inv\n",
    "\n",
    "def ten2mat(tensor, mode):\n",
    "    return np.reshape(np.moveaxis(tensor, mode, 0), (tensor.shape[mode], -1), order = 'F')\n",
    "\n",
    "def mat2ten(mat, tensor_size, mode):\n",
    "    index = list()\n",
    "    index.append(mode)\n",
    "    for i in range(tensor_size.shape[0]):\n",
    "        if i != mode:\n",
    "            index.append(i)\n",
    "    return np.moveaxis(np.reshape(mat, list(tensor_size[index]), order = 'F'), 0, mode)\n",
    "\n",
    "def svt_tnn(mat, alpha, rho, theta):\n",
    "    \"\"\"This is a Numpy dependent singular value thresholding (SVT) process.\"\"\"\n",
    "    u, s, v = np.linalg.svd(mat, full_matrices = 0)\n",
    "    vec = s.copy()\n",
    "    vec[theta :] = s[theta :] - alpha / rho\n",
    "    vec[vec < 0] = 0\n",
    "    return u @ np.diag(vec) @ v\n",
    "\n",
    "def compute_rmse(var, var_hat):\n",
    "    return np.sqrt(np.sum((var - var_hat) ** 2) / var.shape[0])\n",
    "\n",
    "def compute_mape(var, var_hat):\n",
    "    return np.sum(np.abs(var - var_hat) / var) / var.shape[0]\n",
    "\n",
    "def LRTC(dense_tensor, sparse_tensor, alpha, rho, theta, \n",
    "         epsilon = 1e-4, maxiter = 100):\n",
    "    \"\"\"Low-Rank Tenor Completion with Truncated Nuclear Norm, LRTC-TNN.\"\"\"\n",
    "    \n",
    "    dim = np.array(sparse_tensor.shape)\n",
    "    pos_missing = np.where(sparse_tensor == 0)\n",
    "    pos_test = np.where((dense_tensor != 0) & (sparse_tensor == 0))\n",
    "    \n",
    "    X = np.zeros(np.insert(dim, 0, len(dim))) # \\boldsymbol{\\mathcal{X}}\n",
    "    T = np.zeros(np.insert(dim, 0, len(dim))) # \\boldsymbol{\\mathcal{T}}\n",
    "    Z = sparse_tensor.copy()\n",
    "    last_tensor = sparse_tensor.copy()\n",
    "    snorm = np.sqrt(np.sum(sparse_tensor ** 2))\n",
    "    it = 0\n",
    "    while True:\n",
    "        rho = min(rho * 1.05, 1e5)\n",
    "        for k in range(len(dim)):\n",
    "            X[k] = mat2ten(svt_tnn(ten2mat(Z - T[k] / rho, k), alpha[k], rho, theta), dim, k)\n",
    "        Z[pos_missing] = np.mean(X + T / rho, axis = 0)[pos_missing]\n",
    "        T = T + rho * (X - np.broadcast_to(Z, np.insert(dim, 0, len(dim))))\n",
    "        tensor_hat = np.einsum('k, kmnt -> mnt', alpha, X)\n",
    "        tol = np.sqrt(np.sum((tensor_hat - last_tensor) ** 2)) / snorm\n",
    "        last_tensor = tensor_hat.copy()\n",
    "        it += 1\n",
    "        if (it + 1) % 50 == 0:\n",
    "            print('Iter: {}'.format(it + 1))\n",
    "            print('MAPE: {:.6}'.format(compute_mape(dense_tensor[pos_test], tensor_hat[pos_test])))\n",
    "            print('RMSE: {:.6}'.format(compute_rmse(dense_tensor[pos_test], tensor_hat[pos_test])))\n",
    "            print()\n",
    "        if (tol < epsilon) or (it >= maxiter):\n",
    "            break\n",
    "\n",
    "    print('Imputation MAPE: {:.6}'.format(compute_mape(dense_tensor[pos_test], tensor_hat[pos_test])))\n",
    "    print('Imputation RMSE: {:.6}'.format(compute_rmse(dense_tensor[pos_test], tensor_hat[pos_test])))\n",
    "    print()\n",
    "    \n",
    "    return tensor_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On the Seattle Freeway Traffic Speed Dataset\n",
    "\n",
    "### Random Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "for r in [0.3, 0.7, 0.9]:\n",
    "    print('Missing rate = {}'.format(r))\n",
    "    missing_rate = r\n",
    "\n",
    "    ## Random missing (RM)\n",
    "    dense_tensor = np.load('tensor.npz')['arr_0'].transpose(0, 2, 1)\n",
    "    dim1, dim2, dim3 = dense_tensor.shape\n",
    "    np.random.seed(1000)\n",
    "    sparse_tensor = dense_tensor * np.round(np.random.rand(dim1, dim2, dim3) + 0.5 - missing_rate)\n",
    "\n",
    "    for theta in [5, 10, 15, 20, 25]:\n",
    "        print('theta = {}'.format(theta))\n",
    "        start = time.time()\n",
    "        alpha = np.ones(3) / 3\n",
    "        lmbda = 1e-5\n",
    "        tensor_hat = LRTC(dense_tensor[:, :, : 14], sparse_tensor[:, :, : 14],\n",
    "                          alpha, lmbda, theta)\n",
    "        end = time.time()\n",
    "        print('Running time: %d seconds'%(end - start))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "for r in [0.3]:\n",
    "    print('Missing rate = {}'.format(r))\n",
    "    missing_rate = r\n",
    "\n",
    "    ## Random missing (RM)\n",
    "    dense_tensor = np.load('tensor.npz')['arr_0'].transpose(0, 2, 1)\n",
    "    dim1, dim2, dim3 = dense_tensor.shape\n",
    "    np.random.seed(1000)\n",
    "    sparse_tensor = dense_tensor * np.round(np.random.rand(dim1, dim2, dim3) + 0.5 - missing_rate)\n",
    "\n",
    "    for theta in [5]:\n",
    "        print('theta = {}'.format(theta))\n",
    "        start = time.time()\n",
    "        alpha = np.ones(3) / 3\n",
    "        lmbda = 1e-5\n",
    "        tensor_hat = LRTC(dense_tensor[:, :, 14 :], sparse_tensor[:, :, 14 :],\n",
    "                          alpha, lmbda, theta)\n",
    "        end = time.time()\n",
    "        print('Running time: %d seconds'%(end - start))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-Random Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "for r in [0.3, 0.7]:\n",
    "    print('Missing rate = {}'.format(r))\n",
    "    missing_rate = r\n",
    "\n",
    "    ## Non-random Missing (NM)\n",
    "    dense_tensor = np.load('tensor.npz')['arr_0'].transpose(0, 2, 1)\n",
    "    dim1, dim2, dim3 = dense_tensor.shape\n",
    "    np.random.seed(1000)\n",
    "    sparse_tensor = dense_tensor * np.round(np.random.rand(dim1, dim3) + 0.5 - missing_rate)[:, None, :]\n",
    "\n",
    "    for theta in [5, 10, 15, 20, 25]:\n",
    "        print('theta = {}'.format(theta))\n",
    "        start = time.time()\n",
    "        alpha = np.ones(3) / 3\n",
    "        lmbda = 1e-5\n",
    "        tensor_hat = LRTC(dense_tensor[:, :, : 14], sparse_tensor[:, :, : 14],\n",
    "                          alpha, lmbda, theta)\n",
    "        end = time.time()\n",
    "        print('Running time: %d seconds'%(end - start))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Block-Out Missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "for r in [0.3]:\n",
    "    print('Missing rate = {}'.format(r))\n",
    "    missing_rate = r\n",
    "\n",
    "    ## Block-out Missing (BM)\n",
    "    dense_tensor = np.load('tensor.npz')['arr_0'].transpose(0, 2, 1)\n",
    "    dim1, dim2, dim3 = dense_tensor.shape\n",
    "    block_window = 12\n",
    "    np.random.seed(1000)\n",
    "    vec = np.random.rand(int(dim2 * dim3 / block_window))\n",
    "    temp = np.array([vec] * block_window)\n",
    "    vec = temp.reshape([dim2 * dim3], order = 'F')\n",
    "    sparse_tensor = dense_tensor * mat2ten(np.ones((dim1, dim2 * dim3)) * np.round(vec + 0.5 - missing_rate)[None, :], np.array([dim1, dim2, dim3]), 0)\n",
    "\n",
    "    for theta in [5, 10, 15, 20, 25]:\n",
    "        print('theta = {}'.format(theta))\n",
    "        start = time.time()\n",
    "        alpha = np.ones(3) / 3\n",
    "        lmbda = 1e-5\n",
    "        tensor_hat = LRTC(dense_tensor[:, :, : 14], sparse_tensor[:, :, : 14],\n",
    "                          alpha, lmbda, theta)\n",
    "        end = time.time()\n",
    "        print('Running time: %d seconds'%(end - start))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On the Portland Traffic Volume Dataset\n",
    "\n",
    "### Random Missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "for r in [0.3, 0.7, 0.9]:\n",
    "    print('Missing rate = {}'.format(r))\n",
    "    missing_rate = r\n",
    "\n",
    "    # Random Missing (RM)\n",
    "    dense_mat = np.load('volume.npy')\n",
    "    dim1, dim2 = dense_mat.shape\n",
    "    dim = np.array([dim1, 96, 31])\n",
    "    dense_tensor = mat2ten(dense_mat, dim, 0)\n",
    "    np.random.seed(1000)\n",
    "    sparse_tensor = mat2ten(dense_mat * np.round(np.random.rand(dim1, dim2) + 0.5 - missing_rate), dim, 0)\n",
    "\n",
    "    for theta in [5, 10, 15, 20, 25]:\n",
    "        print('theta = {}'.format(theta))\n",
    "        start = time.time()\n",
    "        alpha = np.ones(3) / 3\n",
    "        lmbda = 1e-5\n",
    "        tensor_hat = LRTC(dense_tensor[:, :, : 14], sparse_tensor[:, :, : 14],\n",
    "                          alpha, lmbda, theta)\n",
    "        end = time.time()\n",
    "        print('Running time: %d seconds'%(end - start))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-Random Missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "for r in [0.3, 0.7]:\n",
    "    print('Missing rate = {}'.format(r))\n",
    "    missing_rate = r\n",
    "\n",
    "    # Non-random Missing (NM)\n",
    "    dense_mat = np.load('volume.npy')\n",
    "    dim1, dim2 = dense_mat.shape\n",
    "    dim = np.array([dim1, 96, 31])\n",
    "    dense_tensor = mat2ten(dense_mat, dim, 0)\n",
    "    np.random.seed(1000)\n",
    "    sparse_tensor = dense_tensor * np.round(np.random.rand(dim1, dim[2]) + 0.5 - missing_rate)[:, None, :]\n",
    "\n",
    "    for theta in [5, 10, 15, 20, 25]:\n",
    "        print('theta = {}'.format(theta))\n",
    "        start = time.time()\n",
    "        alpha = np.ones(3) / 3\n",
    "        lmbda = 1e-5\n",
    "        tensor_hat = LRTC(dense_tensor[:, :, : 14], sparse_tensor[:, :, : 14],\n",
    "                          alpha, lmbda, theta)\n",
    "        end = time.time()\n",
    "        print('Running time: %d seconds'%(end - start))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Block-Out Missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "for r in [0.3]:\n",
    "    print('Missing rate = {}'.format(r))\n",
    "    missing_rate = r\n",
    "\n",
    "    ## Block-out Missing (BM)\n",
    "    dense_mat = np.load('volume.npy')\n",
    "    dim1, dim2 = dense_mat.shape\n",
    "    dim = np.array([dim1, 96, 31])\n",
    "    dense_tensor = mat2ten(dense_mat, dim, 0)\n",
    "    block_window = 4\n",
    "    np.random.seed(1000)\n",
    "    vec = np.random.rand(int(dim2 / block_window))\n",
    "    temp = np.array([vec] * block_window)\n",
    "    vec = temp.reshape([dim2], order = 'F')\n",
    "    sparse_tensor = mat2ten(dense_mat * np.round(vec + 0.5 - missing_rate)[None, :], dim, 0)\n",
    "\n",
    "    for theta in [5, 10, 15, 20, 25]:\n",
    "        print('theta = {}'.format(theta))\n",
    "        start = time.time()\n",
    "        alpha = np.ones(3) / 3\n",
    "        lmbda = 1e-5\n",
    "        tensor_hat = LRTC(dense_tensor[:, :, : 14], sparse_tensor[:, :, : 14],\n",
    "                          alpha, lmbda, theta)\n",
    "        end = time.time()\n",
    "        print('Running time: %d seconds'%(end - start))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### License\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>This work is released under the MIT license.</b>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
